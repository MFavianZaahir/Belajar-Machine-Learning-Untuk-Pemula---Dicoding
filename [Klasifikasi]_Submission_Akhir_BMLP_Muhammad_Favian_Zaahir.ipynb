{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     ID  Year_Birth   Education Marital_Status     Income  Kidhome  Teenhome  \\\n",
            "0  5524        1957  Graduation         Single  23.979483        0         0   \n",
            "1  2174        1954  Graduation         Single  23.703774        1         1   \n",
            "2  4141        1965  Graduation       Together  24.232975        0         0   \n",
            "3  6182        1984  Graduation       Together  23.030763        1         0   \n",
            "4  5324        1981         PhD        Married  23.982721        1         0   \n",
            "\n",
            "  Dt_Customer      Recency  MntWines  ...  Age     Tenure  TotalChildren  \\\n",
            "0  2012-09-04  1728.556636       635  ...   68  11.814468       0.950446   \n",
            "1  2014-03-08  1149.436891        11  ...   71  10.123465       2.453716   \n",
            "2  2013-08-21   801.965044       426  ...   60  11.092727       0.950446   \n",
            "3  2014-02-10   801.965044        11  ...   41  10.320622       1.702081   \n",
            "4  2014-01-19  2770.972177       173  ...   44  10.460688       1.702081   \n",
            "\n",
            "   TotalSpent  TotalPurchases  Education_Encoded  Marital_Status_Encoded  \\\n",
            "0   16.483563      171.027961           2.505622                0.646664   \n",
            "1   10.519404       41.353582           2.505622                0.646664   \n",
            "2   15.405174      156.619696           2.505622                1.124670   \n",
            "3   11.484991       55.761846           2.505622                1.124670   \n",
            "4   14.511201      113.394904           4.252262                1.124670   \n",
            "\n",
            "   Cluster  Income_Spent_Ratio  WebPurchase_Frequency  \n",
            "0        1            0.687403               0.677136  \n",
            "1        0            0.443786               0.098780  \n",
            "2        1            0.635711               0.721193  \n",
            "3        0            0.498680               0.193787  \n",
            "4        1            0.605069               0.477980  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('Dataset_clustering.csv', sep=',')\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: (1792, 38), Testing set: (448, 38)\n"
          ]
        }
      ],
      "source": [
        "X = data.drop('Cluster', axis=1)\n",
        "y = data['Cluster']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [],
      "source": [
        "X_train_processed = X_train.drop(['Education', 'Marital_Status', 'Dt_Customer'], axis=1)\n",
        "X_test_processed = X_test.drop(['Education', 'Marital_Status', 'Dt_Customer'], axis=1)\n",
        "\n",
        "X_train_processed = X_train_processed.fillna(X_train_processed.mean())\n",
        "X_test_processed = X_test_processed.fillna(X_test_processed.mean())\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "rf_model.fit(X_train_processed, y_train)\n",
        "\n",
        "y_train_pred_rf = rf_model.predict(X_train_processed)\n",
        "y_test_pred_rf = rf_model.predict(X_test_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\favia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "lr_model.fit(X_train_processed, y_train)\n",
        "\n",
        "y_train_pred_lr = lr_model.predict(X_train_processed)\n",
        "y_test_pred_lr = lr_model.predict(X_test_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **c. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Performance:\n",
            "Training Accuracy: 1.00\n",
            "Training F1-Score: 1.00\n",
            "Testing Accuracy: 0.97\n",
            "Testing F1-Score: 0.97\n",
            "\n",
            "Classification Report (Testing):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       214\n",
            "           1       0.97      0.97      0.97       234\n",
            "\n",
            "    accuracy                           0.97       448\n",
            "   macro avg       0.97      0.97      0.97       448\n",
            "weighted avg       0.97      0.97      0.97       448\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Forest Performance:\")\n",
        "print(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred_rf):.2f}\")\n",
        "print(f\"Training F1-Score: {f1_score(y_train, y_train_pred_rf, average='weighted'):.2f}\")\n",
        "print(f\"Testing Accuracy: {accuracy_score(y_test, y_test_pred_rf):.2f}\")\n",
        "print(f\"Testing F1-Score: {f1_score(y_test, y_test_pred_rf, average='weighted'):.2f}\")\n",
        "print(\"\\nClassification Report (Testing):\")\n",
        "print(classification_report(y_test, y_test_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Performance:\n",
            "Training Accuracy: 0.98\n",
            "Training F1-Score: 0.98\n",
            "Testing Accuracy: 0.97\n",
            "Testing F1-Score: 0.97\n",
            "\n",
            "Classification Report (Testing):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       214\n",
            "           1       0.97      0.97      0.97       234\n",
            "\n",
            "    accuracy                           0.97       448\n",
            "   macro avg       0.97      0.97      0.97       448\n",
            "weighted avg       0.97      0.97      0.97       448\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluasi\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred_lr):.2f}\")\n",
        "print(f\"Training F1-Score: {f1_score(y_train, y_train_pred_lr, average='weighted'):.2f}\")\n",
        "print(f\"Testing Accuracy: {accuracy_score(y_test, y_test_pred_lr):.2f}\")\n",
        "print(f\"Testing F1-Score: {f1_score(y_test, y_test_pred_lr, average='weighted'):.2f}\")\n",
        "print(\"\\nClassification Report (Testing):\")\n",
        "print(classification_report(y_test, y_test_pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_9OwrsXZlz"
      },
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **b. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bikx3LINv5e"
      },
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy (Tuned): 0.96\n",
            "Testing F1-Score (Tuned): 0.96\n"
          ]
        }
      ],
      "source": [
        "X_test_processed = X_test.drop(['Education', 'Marital_Status', 'Dt_Customer'], axis=1)\n",
        "\n",
        "y_test_pred_best_rf = best_rf_model.predict(X_test_processed)\n",
        "print(f\"Testing Accuracy (Tuned): {accuracy_score(y_test, y_test_pred_best_rf):.2f}\")\n",
        "print(f\"Testing F1-Score (Tuned): {f1_score(y_test, y_test_pred_best_rf, average='weighted'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Model  Training Accuracy  Testing Accuracy  \\\n",
            "0        Random Forest           1.000000          0.968750   \n",
            "1  Logistic Regression           0.977679          0.966518   \n",
            "\n",
            "   Training F1-Score  Testing F1-Score  \n",
            "0           1.000000          0.968756  \n",
            "1           0.977676          0.966514  \n"
          ]
        }
      ],
      "source": [
        "results = {\n",
        "    'Model': ['Random Forest', 'Logistic Regression'],\n",
        "    'Training Accuracy': [accuracy_score(y_train, y_train_pred_rf), accuracy_score(y_train, y_train_pred_lr)],\n",
        "    'Testing Accuracy': [accuracy_score(y_test, y_test_pred_rf), accuracy_score(y_test, y_test_pred_lr)],\n",
        "    'Training F1-Score': [f1_score(y_train, y_train_pred_rf, average='weighted'), f1_score(y_train, y_train_pred_lr, average='weighted')],\n",
        "    'Testing F1-Score': [f1_score(y_test, y_test_pred_rf, average='weighted'), f1_score(y_test, y_test_pred_lr, average='weighted')]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
